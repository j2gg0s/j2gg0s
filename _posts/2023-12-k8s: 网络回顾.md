## kube-proxy 负责将目标为 Service 的流量转发给对应 Pod
Linux 下有两种模式 iptables 和 ipvs,
ref [Virtual IPs and Service Proxies](https://kubernetes.io/docs/reference/networking/virtual-ips/).
1.28 依然使用 iptables 做为默认选项, 但 ipvs 做负载均衡的时间复杂度是 O(1), 而 iptables 是 O(n).

[IPVS: How Kubernetes Services Direct Traffic to Pods](https://dustinspecker.com/posts/ipvs-how-kubernetes-services-direct-traffic-to-pods/)
讲述了一个从零开始的例子, 非常有助于理解 ipvs 等相关内容.

kube-proxy 监听 Service, EndpointSlice 等资源, 构建 ipvs 相关规则. 一个例子:
```shell
# k get -n dev svc pong
NAME   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
pong   ClusterIP   172.23.165.141   <none>        80/TCP    6h51m
# k get -n dev pods -l app=pong -o wide
NAME                    READY   STATUS    RESTARTS   AGE     IP             NODE           NOMINATED NODE   READINESS GATES
pong-5c78875d77-gzczj   2/2     Running   0          6h51m   172.22.1.142   10.30.180.55   <none>           <none>
# ipvsadm --list -t 172.23.165.141:http
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  172.23.165.141:http rr
  -> 172.22.1.142:webcache        Masq    1      0          0
```

## iptables
iptables 依赖 netfilter, Linux 内核提供的一系列和网络相关的钩子, 来实现相关功能.

netfilter 包括 5 个关键节点:
- NF_IP_PRE_ROUTING: 在 rouing 前
- NF_IP_LOCAL_IN: routing 后, 如果目标是本机
- NF_IP_FORWARD: routing 后, 如果应该被转发
- NF_IP_LOCAL_OUT: 本机发出的流量
- NF_IP_POST_ROUTING: 本机发出或者转发的流量, 在 FORWARD/OUTPUT 之后

iptables 的 5 个默认 chain 对应上述的 5 个节点:
- PREROUTING    -> NF_IP_PRE_ROUTING
- INPUT         -> NF_IP_LOCAL_IN
- FORWARD       -> NF_IP_FORWARD
- OUTPUT        -> NF_IP_LOCAL_OUT
- POSTROUTING   -> NF_IP_POST_ROUTING

iptables 的概念有 table, chain, rule, match, target 等.

table 由 chain 组成, 按功能分为 5 个:
- Filter 内的规则用来确定是否应该拒绝流量
- NAT (network address translation) 确定是否需要改写流量的目的地
- Raw 提供在 conntrack 之前对包进行操作的时机
- Mangle 用来修改 IP Header, 我未关注
- Security 安全相关, 我未关注

conntrack 是一个按链接维护状态的模块, 常见的状态包括:
- NEW 新建链接的包
- ESTABLISHED 包属于已建立的链接
- SNAT 来源地址被修改
- DNAT 目标地址被修改

除了我们上述说的 5 个自带的 chain, 用户也可以自定义 chain.
chain 由 rule 组成, rule 由 match 和 target 组成.

包在经过上述 netfilter 的节点时, 会执行对应 chain 中的 rule.
如果 match 符合, 则执行 target.

target 分为两大类:
- 终止目标, 如 ACCEPT, RETURN, REJECT 等, 执行后控制权返回给 netfilter
- 非终止目标, 如 JUMP, MARK 等, 执行后继续执行 chain

MASQUERADE 是一个稍微复杂的 target, 它的作用类似 SNAT, 但无需指定特定 IP.
`iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE`
的含义就是将所有经过 eth0 出口的包的源 IP 替换.

## k8s 委托 CNI Plugin 为 Service&Pod 分配 IP, 并解决访问问题
[Container Network Interface](https://github.com/containernetworking/cni) (CNI)
是针对 Linux 容器网络的插件标准.
[Container Runtime](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)
使用配置的 CNI Plugin 去实现 k8s 的网络模型.

containerd 的默认配置文件位于 `/etc/containerd/config.toml`,
默认的 CNI Plugin 配置文件位于 `/etc/cni/net.d/`,
默认的 CNI Plugin 可执行文件位于 `/opt/cni/bin/`.

以使用 flannel 做为 CNI Plugin 的配置文件为例:
```shell
cat /etc/cni/net.d/10-flannel.conflist
{
  "name": "cbr0",
  "cniVersion": "0.3.1",
  "plugins": [
    {
      "type": "flannel",
      "delegate": {
        "hairpinMode": true,
        "isDefaultGateway": true
      }
    },
    {
      "type": "portmap",
      "capabilities": {
        "portMappings": true
      }
    }
  ]
}
```
结合 CNI 配置文件格式说明 [Network configuration format](https://github.com/containernetworking/cni/blob/main/SPEC.md#section-1-network-configuration-format),
我们可以知道上述配置文件指定了两个插件 flannel 和 portmap.

其中 [portmap](https://www.cni.dev/plugins/current/meta/portmap/) 是 CNI 自带的一个插件, 用于将宿主机的某个端口映射到容器端口.

[flannel](https://github.com/flannel-io/flannel/blob/master/Documentation/configuration.md) 是一个著名的第三方插件,
负责为 pod 分配 IP, 并处理对这些 IP 的访问. 根据官方的 Yaml 安装后, flannel 的配置文件保存在 ConfigMap 中:
```shell
k get -n kube-flannel cm kube-flannel-cfg -o json | jq '.data["net-conf.json"]' -r
{
  "Network": "172.22.0.0/16",
  "Backend": {
    "Type": "host-gw"
  }
}
```
上述配置中指定的 Pod 互通方式是 [host-gw](https://github.com/flannel-io/flannel/blob/master/Documentation/backends.md#host-gw),
即通过 iptables 将访问 Pod 的包转发到对应宿主机后, 再由宿主机转发到对应 Pod.
