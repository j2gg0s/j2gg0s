GPU 在特定场景下, 相较于 CPU 有碾压性的优势.

### GPU 的计算优势
以 Transformer 的核心注意力公式来入手分析.
$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$
其包括三个关键步骤:
1. `S = QK^T`, 对应矩阵乘法, 在自注意力中, Q&K 的形状都是 Nxd, 计算复杂度为 `NxdxN`
2. `P = softmax(S)`, softmax 是将任意实数向量转化为概率分布, 即对 S 的每一行, 进行`e^(x_i) / sum(e^(x_j) for all j)`
3. `O = PV`, 对应矩阵乘法

以 FLUX 为例, 当生成图片分辨率为 1024x1024 时， N 为 4352, d 为 3072,
那么一次注意力计算需要的浮点数运算在 `4 x (4352 x 4352 x 3072) = 232.8 × 10⁹ ≈ 233 GFLOP`.

FLUX 有 19+38 个 transformer block, 生图步数假设为 50,
则一次生图需要 `50 x (19x2 + 38) x 233 GFLOP ≈ 885 TFLOP`.

以 A100 的理论算力 312 TFLOPS 计算, 大概需要 2.8 秒, 实际考虑带宽等限制, 大概需要 10 多秒.
而当前高端 CPU 的浮点数算力仅为 0.5 TFLOPS 左右,
对应的理论计算时间会扩大到 30 分钟.

### GPU 的优势来源
这种碾压性的优势自何处来呢?
粗浅的理解是, GPU 有多的多的多的计算核心.
以 A100 为例, 其有 `108 x 64 = 6912` 个 CUDA core 来负责计算.
而 CPU 多核还处于 16/32 这个数量级别.

为了利用如此多的计算核心, 我们在代码中会使用更多数量级的线程.
FLUX 在生图时, 通常会启用 100k ~ 200k 的线程.

对 CPU 熟悉的朋友肯定会回忆起那个知识点:
更多的线程并不会导致更高的利用率, 频繁的线程切换只会导致计算资源浪费.
即使在 IO 密集的应用中, 线程和核心的推荐比例一般也仅在 2:1.

但这条法则在 GPU 中并不适用, 线程切换的成本无限接近于 0.

### 无成本的线程切换
为了理解这一点, 我们需要理解 GPU 的物理架构和编程模型.

GPU 将独立的计算单元称为 SM, Streaming Multiprocessors.
每个 SM 下包括计算核心, 寄存器和共享内存.
以 A100 为例, 其有 108 个 SM, 每个 SM 包括:
- 64 个 CUDA Core 和 4 个 Tensor Core 负责计算
- 256KB 寄存器, 即 65536 个 32 位寄存器
- 至多 164KB 的共享内存

在编程模型中, 在 thread 上提出了 Thread Block 的概念,
一个 block 会包括多个 thread.

在执行时, 同一个 block 下的 thread 一定在同一个 SM 上执行.
当一个 block 被分配到一个 SM 时, 其下的每一个 thread 都会被分配到具体的, 独占的寄存器.
随后切换 Core 上执行的线程时, 并不需要切换上下文, 上下文会被保留在寄存器中.

同时, 为了优化多线程执行中需要缓存和获取的指令集数量,
GPU 采用 SIMT, Single Instruction Multiple Threads.
同一 SM 上的 32 个线程被归为一个 Warp, 执行相同的指令, 共享同一个 PC, Program Counter.

总的来说, GPU 通过更多的寄存器, 将线程的上下文永驻, 实现切换的零成本.

### 其他优势来源
除了零成本的线程切换外, GPU 的优势还来自于:
- 更高的内存带宽 (A100: 2TB/s vs CPU DDR5: ~100GB/s, 约 20 倍差距), 使得 SM 可以更快地从 HBM 读取/写入数据
- Tensor Core 对矩阵运算等的优化
